"""
reader.pyt
Claudia Espinoza, claudia.espinoza@meduniwien.ac.at

Last modifcation: 4:38 PM 11/27/2020

1. Contains functions for reading TTl from the behavioral task 
2. Contains a class to load binary files recorded with Open Ephys

Example:
>>> from fleximaus import reader as rd
>>> myexp = rd.TTL_reader() --> Loading a general TTL reder with the INTAN and Phenosoft info

#2. Loading the reader of the TTL rewards
>>> reward = rd.TTL_reward()

#3. Loading the trials epochs classifier: correct, incorrect responded and non responded, not initialized
>>> Init_trials, Trial_epoch = rd.epochs(myexp)

#4. Reading info from clusters (reading Phy output)
>>> clustersInfo = rd.ClusterReader(mydir = 'sorting\clustering')

#5. Loading spike times only from good clusters
>>> myClustspk = clustersInfo.clust_time()
"""
import glob
import os
import pandas as pd
import xlrd
import numpy as np
from pathlib import Path


mytest = np.arange(10,20)

def TTL_reader(debug=False):
    """
    It reads TTL signals from channels two, containing all TTL signals from the intan file
    and match the information with the Phenosoft file.
    This procedure requred to match the information because the epoch transition: 
    "start", "Ã«nd" and "wheel not stopping" from Phenosoft do not trigger a TTL signal in the INTAN
    Important, in the rule stwiching protocol there are two "start", at the beginning of each rule and 
    one "end" at the end of the recording.
    Information from the INTAN file was read it from the channel 2.
    -----------------------------------------------------------------------------------------
    Input:
    There is a debug option implemented by default set in False. To get this information type TRUE
    e.g. TTL_reader (True)
    The file has to be open in a folder containing at two files:
    1) 'board-DIGITAL-IN-02.dat' --> INTAN file containing the TTL signals from channel 2 
    2) 'AK4801EDSS_RuleSwitch-20.06.22.csv' --> The CSV file output from Phenosoft
    ------------------------------------------------------------------------------------------
    Output:
    When debug True will print thre trials numbers in the INTAN file and Phenossoft. Check correspondance.
    A data frame containing six columns:
    1) "Transition": name of the behavioral trial's epochs
    2) "Code" for each epoch:
        1 = TIstarts/ 2 = IND-CUE_pres_start/ 3 = SOUND_start/ 4 = resp-time-window_start/
        5 = rewPERIODstart/ 6 = PRPstarts/ 7 = TimeOUTstarts/ 8 = ITIstarts/ 9 =NOresponse/
        10 = start/ 11 = wheelISnotSTOPPING/ 12 = end.
    3) "Time Phenosoft": show the time that phenosoft recorded information (in hour:minutes:
        seconds: fraction of seconds) e.g: 16:39:39:246000  
    4) "TTLtimeMatch(ms)": Information generated by INTAN converted in miliseconds. Original 
        information comes in sample points (at 20 KHz, which means the value divided by 20)
        Values were match to the Phenosoft output by adding nan values for the trails that
        do not receive a TTL signal
    5) "TTLraw": It gives the same information than "TTLtimeMatch(ms)" but in sampling points
    5) "EpochsDiffPheno(sec/ms)": It contains the time difference between the Phenosoft epoch 
        information. The last three digits give information in miliseconds, the fourth digit in second.
    6) "TTLstartDIFF (ms)": Time difference in ms obtained from the TTL INTAN signals. It was considered 
        only the time of beginning of the signal (TTL start)
    
    """    
    # 1. READING TTL SIGNALS FROM INTAN --> ONLY CHANNEL TWO
    # 1A. Reading file data
    with open('board-DIGITAL-IN-02.dat', 'rb') as fp:
        rec_ch2 = np.fromfile(fp, np.dtype('int16')) # will transform to 16-bit integers 
    
    # 1B. It creates a list containing 0, 1 and -1. 1 it is where the TTL start and -1 means when the TTL stops
    diff_ch2 = [x - rec_ch2[i - 1] for i, x in enumerate(rec_ch2)][1:] 
    diff2 = np.array(diff_ch2) # creates a np array. 
    
    # 1C. Define indices for the beginning and the end of the TTL signals (in an 1D array)
    TTLStart = np.concatenate(np.argwhere(diff2 == 1))
    TTLEnd = np.concatenate(np.argwhere(diff2 == -1))
    TTLDiff = (TTLEnd - TTLStart)/20 #ttl 200 ms. It defines the duration of each TTL signal
    TTLStart_ms = [ "{:0.3f}".format(x) for x in TTLStart/20. ]
    TTLstartDiff = np.diff(TTLStart)/20 # to get values in ms
    
    
    # 2. IMPORTING BEHAVIORAL DATA FROM PHENOSOFT
    # DATA FORMATING
    # 2A. Selecting the indexes of the column that will be eliminated from the CSV file 
    cols1 = [i for i in range(1,13)]
    cols2 = [14,25,38,39,40,41]
    cols =[*cols1,*cols2] # * to unpack the data
    
    # 2B, Reading the file Phenosoft as csv file 
    data = glob.glob("*.csv") # take the name of the csv file. Output is a list, important later unzipp
    mydf = pd.read_csv(*data, delimiter='\;',engine ='python',index_col=None, skiprows=6, header = None, encoding = 'ISO-8859-1' )
    mydf.dropna(axis = 0, how = 'any', inplace = True, thresh=2) # drop rows with more than 2 empty spaces
    mydf2 = mydf.drop(mydf.columns[cols], axis=1) # dropping the previous specified columns
    
    # 2C, Adding headers to the previous file
    headers1 = ['DataTime','trial_seg','IncorObjID','CorrObjID','CORRobjectBRid','CORRobjectSHAPEid',
                'currRULEstate','currRULE_ID','currNINSINSstate','SWITCHnum','RULEswitchTC', 
                'corrAngle','chosenSIDE','CORR','sideCORRobject','trialCOUNT','respCOUNT','outOFtimeCOUNT',
                'rightCOUNT','corrCOUNT','nCORRlast26T_I','maxCORRlast26','nRESPlast26T_I','nRIGHTSlast26T_I']
    mydf2.columns = headers1
    mydf2.index = range(mydf.shape[0])
    
    # 2D. Rewriting the names of the trial epochs transitions as string
    name = mydf2['trial_seg'].astype(str)
    names = [x.replace('\x00','').split('\t') for x in name] # it outputs a list of lists
    SegTrial = [n for sublist in names for n in sublist] # It creates a flat list of names
    
    # 2E. Creates the codes that refers to the names of the epoch trial transitions
    NameTrial = ['TIstarts','IND-CUE_pres_start','SOUND_start','resp-time-window_start',
             'rewPERIODstart','PRPstarts','TimeOUTstarts','ITIstarts','NOresponse',
             'start','wheelISnotSTOPPING','end']
    codeTrial = [i for i in range(1,13)]
    codeName =  dict(zip(NameTrial, codeTrial))

    #Creates a list with numbers instead of string for the trials epochs name
    codes = [(codeName[i] if i in codeName else 0) for i in SegTrial]
           
    # 2F. Reading and writing the time'epochs from a DateTime format
    date = mydf2['DataTime']
    #dates = list(np.flatten([x.replace('\x00','').split('\t') for x in date])) # replaced for the following two lines
    dates = [x.replace('\x00','').split('\t') for x in date]
    dates_flatten = [n for sublist in dates for n in sublist] # It creates a flat list of names
    dates2 = np.array(dates_flatten, dtype = float)

    # it returns date and time (hour, minute and seconds and miliseconds) from excel format
    rtd = list()
    for i in range(len(dates2)):
        python_dtA = xlrd.xldate.xldate_as_datetime(dates2[i], 0)
        rtd.append(python_dtA)
    
    timeString = [rtd[i].strftime("%H:%M:%S:%f") for i in range (len(rtd))] # Times is strings format
    TimeEpochs = np.diff(rtd) #it gets the time differences between epochs transitions
    
    # 2G. Take time difference from the Phenosoft file in ms and second (change format)
    TimeEpochs_Sec_Ms2 = [(i.seconds*1000)+(i.microseconds/1000) for i in TimeEpochs] # transform to ms
    TimeEpochs_Sec_Ms3 = np.insert(TimeEpochs_Sec_Ms2, 0, 0, axis=0)# add 0 to the first position. Diff have 1 value less 
    
    
    # 3. MATCH THE TTL SIGNALS FROM PHENOSOFT TO INTAN
    # 3A. Obtain a list of index with epochs 'start', 'end' and 'nonstopp'. Phenosoft file
    # This list contain the epochs that do not have a TTL signal in the INTAN
    SegTrialArray = np.array(SegTrial)
    Trialstart = np.where(SegTrialArray == 'start') #contains the Start of the trials IMPORTANT!!!
    Trialend = np.where(SegTrialArray == 'end')
    TrialnotStopping = np.where(SegTrialArray == 'wheelISnotSTOPPING')
    TrialnonTTL = np.sort(np.concatenate((Trialstart, Trialend , TrialnotStopping), axis=None))
    
    # 3B.Divide trails containing the TTL that match and not match from the phenosoft file
    # List with all epoch's index except 'start', 'end' and 'nonstopp'
    idxall = list(range (0, len(SegTrial)))
    indextest = [i for i in idxall if i not in TrialnonTTL]
            
    # Numpy array with al the TTL signals and the index that do not match filled with nan
    # TTL match is the raw data in sample points
    TTLmatch = np.full(len(SegTrial),np.nan)
    for a,b in zip(indextest,TTLStart):
        TTLmatch[a] = b
        
    TTLmatch_ms = [ "{:0.3f}".format(x) for x in TTLmatch/20. ] # give information in ms

    
    # 3C. Create time diffeence values in ms for matched TTL vector
    TTLmatchDiff = np.diff(TTLmatch)/20 # to get values in ms. Diff vectors always have one value less!!!
    TTLmatchDiff2 = np.insert(TTLmatchDiff, 0, 0) # add 0 to the first value to do the match with the names
    
    # 3D. creates a dictionary with code and names
    NameTrial = ['TIstarts','IND-CUE_pres_start','SOUND_start','resp-time-window_start',
             'rewPERIODstart','PRPstarts','TimeOUTstarts','ITIstarts','NOresponse',
             'start','wheelISnotSTOPPING','end']
    codeTrial = [i for i in range(1,13)]
    codeName =  dict(zip(NameTrial, codeTrial))

    #Creates a list with numbers instead of string for the trials epochs name
    codes = [(codeName[i] if i in codeName else 0) for i in SegTrial]
    
    # 4 CHECKING INFORMATION 
    # 4A. Data cotaining the dime difference from the INTAN
    if debug:
        print ("The sum of TTL INTAN + trial without TTL shoud be the same of Phenosoft's segments")
        print ('number of TTL INTAN signals =',len(TTLStart))
        print ('number of trial without TTL =',(len(*Trialstart)+ len(*Trialend)+ len(*TrialnotStopping)))
        print ('number of segments Phenosoft =',len(SegTrial))
        print ("Time differences should be -1 value than the vectors from which differences were taken")
        print ('number of TTL INTAN time diff =',len(TTLstartDiff))
        print ('number of segment Phenosoft time difference =',len(TimeEpochs))    

 
    # 5. CREATE A DATA FRAME FOR EASIER DATA VISUALIZATION
    # order: name of the trial, time difference 
    preDataTTL = [SegTrial, codes, timeString, TTLmatch_ms, TTLmatch, TimeEpochs_Sec_Ms3, TTLmatchDiff2] 
    DataTTL = pd.DataFrame(preDataTTL).T
    DataTTL.columns = ["Transition","Code","Time Phenosoft","TTLtimeMatch(ms)","TTLraw (samp point)","EpochsDiffPheno(sec/ms)",
                       "TTLstartDIFF (ms)"]
    
    return DataTTL

    
def TTL_reward(debug=False):
    """
    Select the times for the reward TTL signals 
    The information is obtained from channel one of the digital IN of the INTAN output
    The duration of the TTL signals is 200 ms (always!)    
    The output is a numpy array in sampling point, indicating when reward was delivered
    """
    # 1A. Reading file data from channel 01
    with open('board-DIGITAL-IN-01.dat', 'rb') as fp:
        rec_ch1 = np.fromfile(fp, np.dtype('int16')) 
    
    # 1B. Create a list containing 0, 1 and -1. 1 it is where the TTL start and -1 means when the TTL stops
    diff_ch1 = [x - rec_ch1[i - 1] for i, x in enumerate(rec_ch1)][1:] 
    diff1 = np.array(diff_ch1) # creates a np array. 
    
    # 1C. Define indices for the beginning and the end of the TTL signals (in an 1D array)
    TTLStart1 = np.concatenate(np.argwhere(diff1 == 1))
    TTLEnd1 = np.concatenate(np.argwhere(diff1 == -1))
    if debug:
        print("TTL average duration:","{:.2f}".format(np.mean(TTLEnd1-TTLStart1)),"+-","{:.2f}".format(np.std(TTLEnd1 - TTLStart1))) 
    return TTLStart1


def epochs(exp, debug = False):
    """
    Its divide the behavioral test in four trials types:
    1) correct, incorrect, Non-responded and No-initialized
    2) identify whenthe first and second rule start
    Debug option is by default False. When It is True the output should be:
    True/True/True/True. If something False, check the files
    
    Epoch's trial Codes: 
    1 =TIstarts/ 2 =IND-CUE_pres_start/ 3 =SOUND_start/ 4 =resp-time-window_start/
    5 =ewPERIODstart/ 6 =PRPstarts/ 7 =TimeOUTstarts/ 8 =ITIstarts/ 9 =NOresponse/
    10 =start/ 11 =wheelISnotSTOPPING/ 12 =end.
    
    Trials
    I: Correct trials --> 1,2,3,4,5,6,8 (lenght = 7)                        
    II: Incorrect trials --> 1,2,3,4,5,6,7,8 (lenght = 8) 
    III: Non responded trial --> 1,2,3,4,9,8 (lenght = 6) 
    IV: Trial not initialized --> 1, 11 (lenght = 2) 
    Rule 1 --> 10 to 10
    Rule 2 --> 10 to 12
    ----------------------------------------------------------
    Input
    exp = a dataframe containing the information of an experiment 
          Use the reader.TTL_reader() 
    e.g = Trials, epochs_s = epochs(exp1)
    -----------------------------------------------------------
    It returns
    Two dictionaries
    1) Index for each epoch stats for the INTAN file
    2) Tuples in sampling point for the INTAN file
          
    """
    # 1. Defining the duration of each trial
    CorrT = [1,2,3,4,5,6,8]
    InCorrT = [1,2,3,4,5,6,7,8]
    NoRespT = [1,2,3,4,9,8]
    NoInitT = [1,11]
    Seg = [CorrT,InCorrT,NoRespT,NoInitT]

    # 2. Getting the index from each trial starts.
    startT = np.concatenate(np.where(exp['Code'] == 10)) # It gives the start index for each rule
    SecondRule = startT[1]+1 # It gets the index for the first trial of the second rule
    endT = np.concatenate(np.where(exp['Code'] == 12)) # It outputs when the Behavioral test stop

    # 3. Trial types will be identified according to their lenght
    initT =  np.concatenate(np.where(exp['Code'] == 1)) #It gives the beginning of each trial
    allTrial = np.concatenate([initT,endT]) # include teh end trial to calculate the lengh of the last trial
    initDiff = np.diff(allTrial) # It gives the code for each trial duration

    # 4. Important --> to consider the start trial and substract this value to the last epoch of the first rule
    SecondRule = startT[1]+1 # Fisrt trial of the second rule
    idx = np.concatenate(np.where(initT == SecondRule)) # it gives the value when the second rule starts
    initDiff [idx[0] - 1] = initDiff [idx[0] - 1] - 1 # substract 1 to the last trial in the Rule 1
    
    # 5. It gives in index of the beginning of the trials
    Trial_idx = [len(i) for i in Seg]  # It gives the lenght of the trials
    Initrials = dict()
    for i in Trial_idx:
        for a,b in zip (initT,initDiff):
            if b == i:
                Initrials.setdefault(i,[]).append(a)
    #Changing name of the keys
    IniTrials_idx = dict(zip(['Correct','InCorrect','NoResp','NoInit'], list(Initrials.values()))) 
                
    # 6. It return a tuple with the sampling point for the beginning and end of the epochs
    epochs_sp = dict()
    for epoch in Trial_idx:
        for ini,diff in zip (initT,initDiff):
            if diff == epoch:
                epochend = ini + epoch 
                epochs_sp.setdefault(epoch,[]).append((exp.iloc[ini][4], exp.iloc[epochend][4])) # 4 th column
    
    #Changing name of the keys
    epochs_s = dict(zip(['Correct','InCorrect','NoResp','NoInit'], list(epochs_sp.values())))
    
    # testing correct clasifitication of the trials
    if debug:
        print('Incorrect trials:',len(np.concatenate(np.where(exp['Transition'] == 
                            'TimeOUTstarts'))) == len(Initrials[Trial_idx[1]]))
        print ('NoResp trials:',len(np.concatenate(np.where(exp['Transition'] == 
                            'NOresponse'))) == len(Initrials[Trial_idx[2]]))
        print('NoInit trials:',len(np.concatenate(np.where(exp['Transition'] == 
                            'wheelISnotSTOPPING'))) == len(Initrials[Trial_idx[3]]))
        print('Correct trials:',len(initT) - (len(Initrials[Trial_idx[1]]) + 
              len(Initrials[Trial_idx[2]]) + 
              len(Initrials[Trial_idx[3]])) == len(Initrials[Trial_idx[0]]))

    
    return (IniTrials_idx, epochs_s)
    
    
class ClusterReader(object):
    """
    It allows to read the clustered activity from Phy files.
    Output a data frame containing the information of only good units
    """
    def __init__(self, mydir = "./"):
        """
        Loads and reads cluster_info.tsv from directory.
        Use:
        from fleximaus import reader as rd
        myclusters = rd.ClusterReader(mydir = 'sorting\clustering')
        myclusters.df
        _______________________________________________________________
        Arguments:
        mydir: (str) indicates the directory of the file cluster_info.tsv
                (ouput directoty from Phy)
       
        Output:
        
        myfile.df = the whole information of the cluster info (includind
        good, noise and mua clusters)
        myfile.good = retrieves the information of good clusters
        this information is also available for mua (myfile.mua) and noise
        myfile.noise 
        """
        self.mydir = mydir
        myfile = Path(mydir, 'cluster_info.tsv')
        self.df = pd.read_csv(myfile, sep = '\t', index_col='id')
        mydf = self.df # it retrives all teh information
        self.good = mydf[mydf.group== 'good'] 
        self.mua = mydf[mydf.group== 'mua']
        self.noise = mydf[mydf.group== 'noise']
    
    
    def clust_time(self):
        """
        Returns a dictionary from ONLY GOOD clusters and spikes times. 
        It reads the output files from Phy:
        'spike_times.npy' and 'spike_clusters.npy'
    
        Arguments:
        ---------------    
        Example: 
        Use ClusterReader to get index:
        1. Myunits = myunit.clust_time(mydir = 'sorting\clustering')
        2. good_idx = myunit.good.index          
        """  
        # Recognize the name's file
        fspk = Path (self.mydir,'spike_times.npy') # file containig the spike times
        fcls = Path (self.mydir,'spike_clusters.npy') # file containing the clusters 
    
        # Data containing the spike information: fisrt the times, the the clusters
        spk_time = np.load(fspk).flatten() # read the spike times files as numpy array
        spk_clust = np.load(fcls) # read the spikes cluster as numpy array
    
        # Creates a dictionary that store all the index for each good cluster
        cluster_idx = dict()
        idx = self.good.index
        for clust in idx:
            cluster_idx [clust] = np.where(spk_clust == clust)
    
        # It creates a dictionary with all the clusters containing the spike times
        cluster_times = dict()
        for key,value in cluster_idx.items():
            cluster_times[key] = spk_time[value]
        
        return (cluster_times) 